   В мережі існують певні сервіси, наприклад [textrazor.com](https://www.textrazor.com), який надає можливість безкоштовно протестувати можливості NLP (demo), та має кілька функціональних переваг. Подальшу інформацію було взято з <https://www.textrazor.com/technology>

* TextRazor використовує сучасні методи обробки природних мов та штучного інтелекту для аналізу, аналізу та вилучення семантичних метаданих із заданого вмісту.

* API TextRazor можна легко інтегрувати з будь-якою мовою, яка може надіслати HTTP-запит і проаналізувати відповідь JSON, завдяки чому можлива потужна аналітика тексту лише за допомогою декількох рядків коду. TextRazor дозволяє витягти будь-яку та всю необхідну інформацію в одному запиті, пов'язуючи витягнуті семантичні метадані, щоб спростити ідентифікацію складних шаблонів.

* Великі дані корисні лише в тому випадку, якщо користувацьке програмне забезпечення може йти в ногу з цим. TextRazor був розроблений з нуля для продуктивності. Написаний на сильно оптимізованому C ++, TextRazor здатний обробляти тисячі слів в секунду. Сервіс створений для автоматичного масштабування до мільярдів запитів у хмарі. 

* Стійка інфраструктура TextRazor побудована на хмарі Amazon Web Services і фізичному обладнанні. TextRazor розроблений для забезпечення високої доступності та послідовності продуктивності для аналізу тисяч, мільйонів або мільярдів щоденних документів.

* TextRazor дозволяє додавати назви продуктів, людей, компаній, спеціальні правила класифікації та вдосконалені мовні зразки. Інтегрований двигун Prolog дозволяє швидко поєднувати результати TextRazor з надійною логікою, призначеною для користувача. 

   Подальшу інформацію було взято з <https://habr.com/ru/post/349864/>

Для витягування слів з російського тексту рішень небагато. Є рішення у Томіта-парсері, але там інтеграція з Python незручна. Також з iPavlov є рішення, але імена не зводяться до нормальної форми. З витягуванням адрес або посилань на нормативні акти ще складніше.

Наташа – аналог Томіта-парсера для Python і набір готових правил для витягування імен, адрес, дат, сум грошей та інших сутностей. Можна додавати свої правила за допомогою Yargy-парсера.

Зараз є правила для витягування імен, адрес, дат і сум грошей.  Правила для назв організацій і географічних об’єктів нижчої якості. 

У 2016 році проводилося змагання factRuEval-2016 з витягування іменних сутностей. Найкраща F1-міра була більше 0.9. У Наташі результат 0.78 через проблеми з іноземними іменами та складними прізвищами. Для текстів з російськими іменами результат ~0.95.

Проблемою бібліотеки Наташа є обмеженість готовими правилами. Наприклад, не вдасться визначити ««1» липня 2018» як дату, бо в правилах не враховані лапки. Також не вдасться розібрати адресу без назви вулиці.
У таких випадках доводиться доповнювати готові правила та писати свої за допомогою Yargy-парсеру, бібліотеці, яка є основою Наташі.

Yargy-парсер – аналог яндексового Томіта-парсера для Python. Правила для витягування сутностей описуються за допомогою контекстно-вільних граматик і словників.
Граматики в Yargy записуються на спеціальному DSL-і. Застосовуються вони для таких задач як витягування дат в ISO-форматі («2018-03-04», «2014-04-28»).

У парсер вбудовано багато готових предикантів і є можливість додати свої. Для визначення морфології слів використовується pymorphy2.

Парсер також виконує інтерпрепацію, і, наприклад, замість «16 серпня» повертає Date(month=8, day=16). Результат роботи парсера – дерево розбору.
 
Для інтерпретації користувач розвішує на вузли дерева помітки.
 
У прикладі потрібно звести назви років, місяців і днів до числам. Ця процедура називається нормалізацією.
Наприклад, січень – 1, лютий – 2, березень – 3 і так далі.

Також у Yargy є механізм узгодження, наприклад, імен і прізвищ за родом, числом та відмінком.

Рішення Наташі під ліцензією MIT, тобто, можна вільно використовувати, модифікувати і так далі.

Недоліками Наташі є потреба вручну складати правила та повільна швидкість (наприклад, витягування імен у 10 разів повільніше ніж у Томіта-парсера). Також наявні помилки у стандартних правилах.

Адреса проекту на Github — <https://github.com/natasha>.

                                 ВЕСУМ-великий електронний словник української мови


Бере початок з проекту ispell-uk, що його в 90-х роках створила група ентузіастів для перевірки орфографії української мови у відкритій ОС Linux. Багато років цей словник мав єдину функцію — перевіряти орфографію текстів. Але декілька років тому в інший відкритий проект, програму перевірки граматики та стилю LanguageTool, було додано модуль української мови

До проекту долучилася команда створення відкритого корпусу української мови БрУК

Для створення ВЕСУМ-а ми використали два найголовніших джерела: “Граматичний словник української літературної мови. Словозміна” (опублікований 2011 року й удоступнений на Лінгвістичному порталіhttp://www.mova.info/grmasl.aspx) та “Словники України” онлайн (http://lcorp.ulif.org.ua/dictua/).

Зусилля, вкладені в проект, на виході дали без перебільшення унікальний словник:
ОСНОВНІ ЗАСТОСУВАННЯ
• налічує понад 285 тис. лем і постійно поповнюється
• містить інформацію про відмінювання слів
• подає нерекомендовані слова (активні дієприкметники, невдалі кальки тощо) та заміну для них
• охоплює абревіатури та скорочення
• містить інформацію про деякі альтернативні правописні варіанти (дає змогу аналізувати тексти, написані не за чинним правописом, адже низка медій, авторів, видавництв свідомо дотримуються альтернативних правописних правил)
• має велику базу власних імен (зокрема українських імен, по батькові та прізвищ, неукраїнських імен та прізвищ, українських та закордонних топонімів тощо)
• синхронізований з КОАТУУ, зокрема містить назви, що з’явилися внаслідок декомунізації
• має дуже компактну систему позначення відмінювання та тегів для слів, завдяки чому легко додавати нові слова, групувати наявні тощо
• містить інформацію про деякі рідкісні та розмовні форми, наприклад, нестягнені форми прикметників (гарная), та розмовні інфінітиви (поїхать); щоправда, більшість таких форм вимкнено за уставою, оскільки вони мають обмежену форму застосування й часто створюють зайву омонімію (однак за потреби їх можна ввімкнути)
• є відкритим проектом (розміщений на github), тож кожен може долучитися до вдосконалення та використовувати його у своїй роботі.

Інші застосування
• укладання тлумачних, термінологічних, перекладних та інших типів словників (зокрема пошук прикладів вживання)
• різноманітні мовознавчі дослідження
• дослідження і розробки у галузі комп’ютерної лінгвістики (зокрема побудова моделей мови, отримання статистичної інформації)
• довідкові функції та редагування


Структура словника
Словник містить три основні частини:
1. правила зміни суфіксів у парадигмах
2. слова з прапорцями парадигм та додаткових властивостей
3. код генерування повних парадигм із сирцевої інформації (1 та 2)
Наприклад, запис
тракторист /n20.a.p.<
означає, що це відмінюване слово чоловічого роду другої відміни без чергування (і/о), істота, з закінченням -а в родовому відмінку)


Плани розвитку
Завдання на найближче майбутнє:
• наповнення словника: довести обсяг до 300 тис. лем
• додати пошук у словнику через веб-інтерфейс; наразі вже є прототип REST API, лишилося надбудувати UI.

Джерело: https://r2u.org.ua/articles/vesum

